{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d /content/shape_predictor_68_face_landmarks.dat.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qov7fRLPm3F0",
        "outputId": "d91a3c5f-fe0e-4e23-80d3-935d4b77757f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-28 17:06:45--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  52.8MB/s    in 1.2s    \n",
            "\n",
            "2023-03-28 17:06:46 (52.8 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/shape_predictor_68_face_landmarks.dat'\n",
        "predictor = dlib.shape_predictor(model_path)"
      ],
      "metadata": {
        "id": "MKqH5VlFm3IH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AAM 모델 구성\n",
        "def build_aam_model(images):\n",
        "    shapes = []\n",
        "    for img in images:\n",
        "        rects = detector(img, 1)\n",
        "        shape = predictor(img, rects[0])\n",
        "        shape = face_utils.shape_to_np(shape)\n",
        "        shapes.append(shape)\n",
        "    mean_shape = np.mean(shapes, axis=0)\n",
        "    centered_shapes = shapes - mean_shape\n",
        "    cov = np.cov(centered_shapes, rowvar=False)\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
        "    idx = eigenvalues.argsort()[::-1]\n",
        "    eigenvalues = eigenvalues[idx]\n",
        "    eigenvectors = eigenvectors[:, idx]\n",
        "    p = eigenvectors.T.dot(centered_shapes.T)\n",
        "    return mean_shape, eigenvectors, p\n"
      ],
      "metadata": {
        "id": "rifeNZiUm3KW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = dlib.get_frontal_face_detector()"
      ],
      "metadata": {
        "id": "XMWFW9ncm3Mr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 얼굴 템플릿 이미지 다운로드\n",
        "template_imgs = cv2.imread('/content/sel.jpg')\n",
        "template_imgs2 = cv2.imread('/content/sel2.jpg')\n",
        "\n",
        "template1 = cv2.cvtColor(template_imgs, cv2.COLOR_BGR2GRAY)\n",
        "template2 = cv2.cvtColor(template_imgs2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "t1 = template1.reshape(1440 * 1080)\n",
        "t2 = template2.reshape(1440 * 1080)\n",
        "imgs = [t1, t2]\n",
        "# # template_img = cv2.cvtColor(template_imgs ,  cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# template_rects = detector(template_img, 1)\n",
        "# template_shape = predictor(template_img, template_rects[0])\n",
        "# template_shape = face_utils.shape_to_np(template_shape)\n",
        "\n",
        "\n",
        "# template_imgs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnSUhtvxm3Ov",
        "outputId": "5450db3a-c532-4e0a-afac-8e4bf67966ea"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1555200,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_shape, eigenvectors, p = build_aam_model(imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "PK7nGKbWozc7",
        "outputId": "32d61dda-871f-4c23-a810-e62c120acef8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0fb6a8723271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_aam_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-e32f6b7f087e>\u001b[0m in \u001b[0;36mbuild_aam_model\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unsupported image type, must be 8bit gray or RGB image."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = cv2.imread('/content/sel2.jpg')\n",
        "test_rects = detector(test_img, 1)\n",
        "test_shape = predictor(test_img, test_rects[0])\n",
        "test_shape = face_utils.shape_to_np(test_shape)\n"
      ],
      "metadata": {
        "id": "f63FKvJ3ozfI"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AAM model fitting\n",
        "feature_vector = np.zeros(eigenvectors.shape[0])\n",
        "for i in range(len(feature_vector)):\n",
        "    feature_vector[i] = np.dot(p[i], (test_shape - mean_shape).flatten())\n",
        "reconstructed_shape = mean_shape + eigenvectors.dot(feature_vector)\n",
        "M = cv2.estimateAffinePartial2D(reconstructed_shape, template_shape)\n",
        "warped_img = cv2.warpAffine(test_img, M[0], (template_img.shape[1], template_img.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "uvEDICa8ozhV",
        "outputId": "45356bf5-4361-4a25-e629-ec218a4656ae"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-3102af6ffc89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# AAM model fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfeature_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_shape\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreconstructed_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eigenvectors' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JqrR9VOXozjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DYE1E77hozlY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}